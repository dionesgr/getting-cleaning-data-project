Getting and Cleaning Data Project
Source Data:
 The data used in this project can be found at:
 https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip 
 provided by Coursera.org
A full description of data is available at: 
http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones

Data Set
The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. 
Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING)
wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 
3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded 
to label the data manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers 
was selected for generating the training data and 30% the test data. 
The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width
sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and 
body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational 
force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. 
From each window, a vector of features was obtained by calculating variables from the time and frequency domain. 
More details can be found at "features_info.txt".

Attribute Information For each record it is provided:

Triaxial acceleration from the accelerometer (total acceleration) and the estimated body acceleration.
Triaxial Angular velocity from the gyroscope.
A 561-feature vector with time and frequency domain variables.
Its activity label.
An identifier of the subject who carried out the experiment.

The work was performed in five steps:
•	First, all the similar data was merged using the rbind() function. By similar, we address those files having the same number 
of columns and referring to the same entities;
•	Then, only those columns with the mean and standard deviation measures were taken from the whole dataset. After extracting 
these columns, they are given the correct names, taken from features.txt;
•	As activity data was addressed with values 1:6, we tooke the activity names and IDs from activity_labels.txt and they were
substituted in the dataset;
•	On the whole dataset, those columns with vague column names were corrected;
•	Finally, we generate a new dataset with all the average measures for each subject and activity type 
(30 subjects * 6 activities = 180 rows). The output file is called averages_data.txt, and uploaded to this repository.

